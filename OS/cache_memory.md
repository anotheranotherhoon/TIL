## 0. 캐시 메모리(Cache Memory)
> * 캐시(cache)는 데이터를 미리 복사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다.
> * 이를 통해 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고 무언가를 다시 계산하는 시간을 절약할 수 있다.
> * 실제로 메모리와 CPU사이의 속도 차이가 너무 크기 때문에 그 중간에 레지스터 계층을 둬서 속도 차이를 해결한다. 
> * 이렇게 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 캐싱 계층이라고 한다. 
> * ex) 캐시 메모리와 보조기억장치 사이에 있는 주기억장치를 보조기억장치의 캐싱 계층이라고 할 수 있다.

* 캐시 메모리는 CPU 내 또는 외에 존재하는 메모리로써, 메인 메모리와 CPU간의 데이터 속도 향상을 위한 중간 버퍼 역할을 한다. 
* 여기서 'Cache'라는 의미는 보관이나 저장의 의미를 가지고 있다. 
* 캐시 메모리는 이러한 역할을 하는 물리적 장치를 말한다.
* CPU와 메인 메모리 사이에 존재한다고 말할 수 있는데, CPU내에 존재할 수도 있고 역할이나 성능에 따라 CPU밖에 존재할 수도 있다.
* 빠른 CPU의 처리 속도와 상대적으로 느린 메인 메모리에서의 속도의 차이를 극복하는 완충 역할을 해준다. 
* 쉽게 표현하면 CPU는 빠르게 일을 진행하고 있는데, 메인 메모리가 데이터를 가져오고 가져가는게 느려서 캐시 메모리가 중간에 미리 CPU에 전달될 데이터를 들고 서 있는 형태이다.

## 1. 지역성의 원리
* 캐시 계층을 두는 것 말고 캐시를 직접 설정하는 방법
* 자주 사용하는 데이터를 기반으로 설정해야 한다. 자주 사용하는 데이터에 대한 근거가 되는 것은 무엇일까? 그것은 바로 지역성이다. 
* 지역성은 시간 지역성과(temporal locality) 공간 지역성(spatial locality)로 나뉜다.

### 1-1. 시간 지연성
* 시간 지연성은 최근 사용한 데이터에 다시 접근하려는 특성을 말한다.
* 예를 들어 for 반복문으로 이루어진 코드 코드에서 데이터 변수 i에 계속 접근하는 경우 이다.

### 1-2. 공간 지역성
* 공간 지역성은 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성을 말한다. 
* 반복문을 통해 배열 arr의 각 인덱스를 통해 요소마다 i가 할당될 때 해당 배열에 연속적으로 접근하는 경우이다. 
* 
## 2. 캐시 메모리의 성능 결정요소
* 캐시 메모리는 메인 메모리의 일정 블록 사이즈의 데이터를 담아 두었다가 CPU에 워드 사이즈 만큼의 데이터를 전송하게 된다. 
* 이때 이 사이즈들이 캐시의 성능에 영향을 미치게 되는데, 블록 사이즈나 워드 사이즈가 상대적으로 크다면 그만큼 Cache의 Hit Ratio율이 높아지기 때문이다.

* CPU가 필요한 데이터가 Cache Memory 내에 들어와 있으면 'Cache Hit'라 하고 접근하고자 하는 데이터가 없을 경우를 'Cache Miss'라 한다. 이러한 원하는 데이터가 있을 수도 있고 없을 수도 있는데, 이때 원하는 데이터가 Cache에 있을 확률을 'Hit Ratio'라고 한다. 
> * 캐시에서 원하는 데이터를 찾았다면 캐시히트라고 하며, 
> * 해당 데이터가 캐시에 없다면 주메모리로 가서 데이터를 찾아오는 것을 캐시 미스라고 한다. 
> * 캐시히트를 하게 되면 해당 데이터를 제어장치를 거쳐 가져오게 된다. 
> * 캐시 히트의 경우 위치도 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠르다.
> * 반면에 캐시미스가 발생되면 메모리에서 가져오게 되는데, 이는 시스템 버스를 기반으로 작동하기 때문에 느리다.

|요소|내용|
|---|---|
|Cache 크기|Cache Memory의 Size의 크기가 크면 Hit Ratio율과 반비례 관계|
|인출 방식(Fetch Algorithm)|요구 인출(Demand Fetch) : 필요시 요구하여 인출하는 방식<br/>선 인출(Pre-Fetch) : 예상되는 데이터를 미리 인출하는 방식|
|쓰기 정책 (Write Policy)|Write-Through: 주기억 장치와 캐시에 동시에 쓰는 방식. Cache와 메모리의 내용이 항상 일치하며 구성 방법이 단순하다.<br/>Write-Back: 데이터 변경만 캐시에 기록하는 방식. 구성방법이 복잡하다.|
|교체(Replace) 알고리즘|Cache Miss 발생시 기존 메모리와 교체하는 방식.<br/>FIFO, LRU, LFU, Random, Optimal Belady’s MIN(향후 가장 참조 되지 않을 블록을 교체) 등이 있다.|
|캐시매핑|주기억장치의 블록을 적재할 캐시 내의 위치를 지정하는 방법<br/>직접 매핑(direct mapping), 어소시에이티브 매핑(associative mapping), 셋 어소시에이티브 매핑(set associative mapping) 등이 있다.|

## 3. 캐시 매핑
* 캐시 매핑이란 캐시가 히트되기 위해 매핑하는 방법을 말하며 CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고 받을 때를 기반으로 설명한다. 
* 레지스터는 주 메모리에 비하면 굉장히 작고 주 메모리는 굉장히 크기 때문에 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 이 매핑을 어떻게 하느냐가 중요하다.

|이름|설명|
|---|---|
|직접 매핑<sup>directed mapping</sup>|메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20 ... 이런 식으로 매핑하는 것을 말한다. 처리가 빠르지만 충돌 발생이 잦다.|
|연관 매핑<sup>associative mapping</sup>|순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑한다.<br /> 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느리다.|
|집합 연관 매핑<sup>set associative mapping</sup>|직접 매핑과 연관 매핑을 합쳐 놓은 것이다.<br /> 순서는 일치 시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색은 좀 더 효율적이다.<br /> 예를 들어 메모리가 1~100이 있고 캐시가 1~10이 있다면 캐시 1~5에는 1~50의 데이터를 무작위로 저장시키는 것을 말한다.|